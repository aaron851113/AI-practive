{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax practice\n",
    "re:https://github.com/tjwei/CrashCourseML/blob/master/DIY_NN/Softmax.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先隨便算一個R^2 -> R^3 的網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run magic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}1.000&2.000\\\\ 3.000&4.000\\\\ 5.000&6.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weight\n",
    "W = Matrix([1,2],[3,4],[5,6])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}1.000\\\\ 0.000\\\\ -1.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bias\n",
    "b = Vector(1,0,-1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}2.000\\\\ -1.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[ 2.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "x = Vector(2,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任務：計算最後的猜測機率q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.090\\\\ 0.245\\\\ 0.665\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.09003057],\n",
       "       [0.24472847],\n",
       "       [0.66524096]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load solutions/softmax_compute_q.py\n",
    "#參考答案：https://github.com/tjwei/CrashCourseML/blob/master/DIY_NN/solutions/softmax_compute_q.py\n",
    "\n",
    "# Wx+b\n",
    "c = W @ x + b\n",
    "\n",
    "# d = exp(Wx+b)\n",
    "d = np.exp(c)\n",
    "\n",
    "# q = d/sum(d)\n",
    "q = d/d.sum()\n",
    "\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習：\n",
    "設計一個網路\n",
    "    。輸入是二進位 0~15\n",
    "    。輸出依照對於4的餘數分成四類\n",
    "Hint : 可以參考上面 w , b的設定方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}1.000\\\\ 0.000\\\\ 1.000\\\\ 1.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 13\n",
    "#轉為2進位\n",
    "x = Vector(i%2,(i>>1)%2,(i>>2)%2,(i>>3)%2)\n",
    "x #1011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0 predict: 0 ground truth: 0\n",
      "i= 1 predict: 1 ground truth: 1\n",
      "i= 2 predict: 2 ground truth: 2\n",
      "i= 3 predict: 3 ground truth: 3\n",
      "i= 4 predict: 0 ground truth: 0\n",
      "i= 5 predict: 1 ground truth: 1\n",
      "i= 6 predict: 2 ground truth: 2\n",
      "i= 7 predict: 3 ground truth: 3\n",
      "i= 8 predict: 0 ground truth: 0\n",
      "i= 9 predict: 1 ground truth: 1\n",
      "i= 10 predict: 2 ground truth: 2\n",
      "i= 11 predict: 3 ground truth: 3\n",
      "i= 12 predict: 0 ground truth: 0\n",
      "i= 13 predict: 1 ground truth: 1\n",
      "i= 14 predict: 2 ground truth: 2\n",
      "i= 15 predict: 3 ground truth: 3\n"
     ]
    }
   ],
   "source": [
    "#計算\n",
    "W = Matrix([-1,-1,0,0], [1,-1,0,0], [-1,1,0,0], [1,1,0,0])\n",
    "b = Vector(0,0,0,0)\n",
    "for i in range(16):\n",
    "    x = Vector(i%2, (i>>1)%2, (i>>2)%2, (i>>3)%2)\n",
    "    r = W @ x + b\n",
    "    print(\"i=\", i, \"predict:\", r.argmax(), \"ground truth:\", i%4)\n",
    "\n",
    "#參考答案：https://github.com/tjwei/CrashCourseML/blob/master/DIY_NN/solutions/softmax_mod4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent 誤差函數\n",
    "為了要評斷我們的預測的品質，要設計一個評斷誤差的方式 <br /> \n",
    "假設輸入值x對應到的真實類別是y，那我們定義誤差函數 <br />\n",
    "使用<b>Cross Entropy</b>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4932432   0.72711632  0.90136378  0.5354255 ]\n",
      " [-0.32162684  0.19246346  0.23251444 -1.46401507]\n",
      " [-1.09724217  0.14083738 -0.05904267 -0.22846953]]\n",
      "[[-0.21257254]\n",
      " [ 0.83733359]\n",
      " [-0.22814961]]\n"
     ]
    }
   ],
   "source": [
    "#先產生隨機的 W / B\n",
    "W = Matrix(np.random.normal(size=(3,4)))\n",
    "print(W)\n",
    "b = Vector(np.random.normal(size=(3,)))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題：w/b的size為什麼要這樣設定？\n",
    "\n",
    "### 任務：隨便設定一組x,y 跑跑看Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 14\n",
    "x = Vector(i%2, (i>>1)%2, (i>>2)%2, (i>>3)%2)\n",
    "y = i%3\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟：計算q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.371\\\\ 0.186\\\\ 0.443\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.37106728],\n",
       "       [0.18571493],\n",
       "       [0.44321778]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wx+b\n",
    "c = W @ x + b\n",
    "\n",
    "# d = exp(Wx+b)\n",
    "d = np.exp(c)\n",
    "\n",
    "# q = d/sum(d)\n",
    "q = d/d.sum()\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟：計算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.814\\end{pmatrix}"
      ],
      "text/plain": [
       "array([0.81369402])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -np.log(q[y])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟：計算對b的gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.371\\\\ 0.186\\\\ -0.557\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[ 0.37106728],\n",
       "       [ 0.18571493],\n",
       "       [-0.55678222]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_b = q.copy()\n",
    "grad_b[y] -= 1\n",
    "grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟：計算對W的gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.37106728 0.37106728 0.37106728]\n",
      " [0.         0.18571493 0.18571493 0.18571493]\n",
      " [0.         0.44321778 0.44321778 0.44321778]]\n",
      "[0.         0.44321778 0.44321778 0.44321778]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[ 0.         -0.55678222 -0.55678222 -0.55678222]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.000&0.371&0.371&0.371\\\\ 0.000&0.186&0.186&0.186\\\\ 0.000&-0.557&-0.557&-0.557\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[ 0.        ,  0.37106728,  0.37106728,  0.37106728],\n",
       "       [ 0.        ,  0.18571493,  0.18571493,  0.18571493],\n",
       "       [ 0.        , -0.55678222, -0.55678222, -0.55678222]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_W =   q @ x.T\n",
    "print(grad_W)\n",
    "print(grad_W[y])\n",
    "print(x)\n",
    "grad_W[y] -= x.ravel()\n",
    "print(grad_W[y])\n",
    "\n",
    "# or \n",
    "grad_W = grad_b @ x.T\n",
    "grad_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟：更新W,b 個減掉0.5*gradient，然後看看新的loss是否有進步了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "W -= 0.5 * grad_W\n",
    "b -= 0.5 * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原先的q\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.009\\\\ 0.020\\\\ 0.971\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.00930648],\n",
       "       [0.01989374],\n",
       "       [0.97079977]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"原先的q\")\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原先的loss\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.030\\end{pmatrix}"
      ],
      "text/plain": [
       "array([0.02963504])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"原先的loss\")\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新後的q\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.009\\\\ 0.018\\\\ 0.973\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.0086387 ],\n",
       "       [0.01807936],\n",
       "       [0.97328195]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wx+b\n",
    "c = W @ x + b\n",
    "# d = exp(Wx+b)\n",
    "d = np.exp(c)\n",
    "# q = d/sum(d)\n",
    "q = d/d.sum()\n",
    "print(\"更新後的q\")\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新後的loss\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.027\\end{pmatrix}"
      ],
      "text/plain": [
       "array([0.02708147])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -np.log(q[y])\n",
    "loss\n",
    "print(\"更新後的loss\")\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一次訓練多組資料\n",
    "\n",
    "上面只針對一組 x (i=14)來訓練，如果一次對所有x做訓練 <br />\n",
    "通常我們會把組別放在 axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([Vector(i%2,(i>>1)%2,(i>>2)%2,(i>>3)%2) for i in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.000\\\\ 0.000\\\\ 0.000\\\\ 0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}1.000\\\\ 0.000\\\\ 0.000\\\\ 0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 2\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.000\\\\ 1.000\\\\ 0.000\\\\ 0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 3\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}1.000\\\\ 1.000\\\\ 0.000\\\\ 0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 4\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.000\\\\ 0.000\\\\ 1.000\\\\ 0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"i=\",i)\n",
    "    display(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}0.000&1.000&2.000&0.000&1.000&2.000&0.000&1.000&2.000&0.000&1.000&2.000&0.000&1.000&2.000&0.000\\end{pmatrix}"
      ],
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 對應的組別\n",
    "y = np.array([i%3 for i in range(16)])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任務：將訓練向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{bmatrix}[0.404&0.311&0.284]\\\\ [0.351&0.434&0.215]\\\\ [0.337&0.174&0.488]\\\\ [0.324&0.269&0.407]\\\\ [0.353&0.433&0.214]\\\\ [0.286&0.563&0.151]\\\\ [0.326&0.268&0.406]\\\\ [0.294&0.388&0.318]\\\\ [0.346&0.186&0.467]\\\\ [0.329&0.284&0.386]\\\\ [0.242&0.087&0.671]\\\\ [0.250&0.145&0.605]\\\\ [0.331&0.284&0.385]\\\\ [0.295&0.406&0.299]\\\\ [0.252&0.145&0.603]\\\\ [0.250&0.231&0.520]\\end{bmatrix}"
      ],
      "text/plain": [
       "array([[[0.40446299],\n",
       "        [0.31131314],\n",
       "        [0.28422387]],\n",
       "\n",
       "       [[0.35126712],\n",
       "        [0.43410835],\n",
       "        [0.21462453]],\n",
       "\n",
       "       [[0.33732402],\n",
       "        [0.17446661],\n",
       "        [0.48820937]],\n",
       "\n",
       "       [[0.32374631],\n",
       "        [0.26885112],\n",
       "        [0.40740257]],\n",
       "\n",
       "       [[0.35321005],\n",
       "        [0.43277826],\n",
       "        [0.21401169]],\n",
       "\n",
       "       [[0.28619347],\n",
       "        [0.56303329],\n",
       "        [0.15077324]],\n",
       "\n",
       "       [[0.32560095],\n",
       "        [0.26808   ],\n",
       "        [0.40631905]],\n",
       "\n",
       "       [[0.29351361],\n",
       "        [0.38801541],\n",
       "        [0.31847098]],\n",
       "\n",
       "       [[0.34643136],\n",
       "        [0.18626206],\n",
       "        [0.46730657]],\n",
       "\n",
       "       [[0.32936652],\n",
       "        [0.28433389],\n",
       "        [0.38629958]],\n",
       "\n",
       "       [[0.24157642],\n",
       "        [0.08727867],\n",
       "        [0.67114491]],\n",
       "\n",
       "       [[0.25027075],\n",
       "        [0.14517962],\n",
       "        [0.60454963]],\n",
       "\n",
       "       [[0.33123881],\n",
       "        [0.28350592],\n",
       "        [0.38525527]],\n",
       "\n",
       "       [[0.29537632],\n",
       "        [0.40591824],\n",
       "        [0.29870545]],\n",
       "\n",
       "       [[0.2518532 ],\n",
       "        [0.14484875],\n",
       "        [0.60329805]],\n",
       "\n",
       "       [[0.24961143],\n",
       "        [0.23050149],\n",
       "        [0.51988708]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.exp(W@X+b)\n",
    "q = d/d.sum(axis=(1,2),keepdims=True)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{bmatrix}[0.905&1.167&1.258]\\\\ [1.046&0.834&1.539]\\\\ [1.087&1.746&0.717]\\\\ [0.905&1.167&1.258]\\\\ [1.046&0.834&1.539]\\\\ [1.087&1.746&0.717]\\\\ [0.905&1.167&1.258]\\\\ [1.046&0.834&1.539]\\\\ [1.087&1.746&0.717]\\\\ [0.905&1.167&1.258]\\\\ [1.046&0.834&1.539]\\\\ [1.087&1.746&0.717]\\\\ [0.905&1.167&1.258]\\\\ [1.046&0.834&1.539]\\\\ [1.087&1.746&0.717]\\\\ [0.905&1.167&1.258]\\end{bmatrix}"
      ],
      "text/plain": [
       "array([[[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]],\n",
       "\n",
       "       [[1.04620832],\n",
       "        [0.83446112],\n",
       "        [1.53886515]],\n",
       "\n",
       "       [[1.08671132],\n",
       "        [1.74602192],\n",
       "        [0.71701093]],\n",
       "\n",
       "       [[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]],\n",
       "\n",
       "       [[1.04620832],\n",
       "        [0.83446112],\n",
       "        [1.53886515]],\n",
       "\n",
       "       [[1.08671132],\n",
       "        [1.74602192],\n",
       "        [0.71701093]],\n",
       "\n",
       "       [[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]],\n",
       "\n",
       "       [[1.04620832],\n",
       "        [0.83446112],\n",
       "        [1.53886515]],\n",
       "\n",
       "       [[1.08671132],\n",
       "        [1.74602192],\n",
       "        [0.71701093]],\n",
       "\n",
       "       [[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]],\n",
       "\n",
       "       [[1.04620832],\n",
       "        [0.83446112],\n",
       "        [1.53886515]],\n",
       "\n",
       "       [[1.08671132],\n",
       "        [1.74602192],\n",
       "        [0.71701093]],\n",
       "\n",
       "       [[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]],\n",
       "\n",
       "       [[1.04620832],\n",
       "        [0.83446112],\n",
       "        [1.53886515]],\n",
       "\n",
       "       [[1.08671132],\n",
       "        [1.74602192],\n",
       "        [0.71701093]],\n",
       "\n",
       "       [[0.90519504],\n",
       "        [1.16695598],\n",
       "        [1.25799308]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -np.log(q[y])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1422345512581762"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用平均當我們的loss\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}-0.064\\\\ -0.024\\\\ 0.089\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[-0.06430979],\n",
       "       [-0.02447032],\n",
       "       [ 0.08878011]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fancy indexing :p\n",
    "one_y = np.eye(3)[y][..., None]\n",
    "grad_b_all = q - one_y\n",
    "grad_b = grad_b_all.mean(axis=0)\n",
    "grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{pmatrix}-0.039&-0.045&-0.038&-0.044\\\\ -0.018&-0.018&-0.018&-0.015\\\\ 0.056&0.064&0.056&0.059\\end{pmatrix}"
      ],
      "text/plain": [
       "array([[-0.0387909 , -0.04540646, -0.03833764, -0.0440172 ],\n",
       "       [-0.01750366, -0.01829865, -0.01770741, -0.01451071],\n",
       "       [ 0.05629457,  0.0637051 ,  0.05604505,  0.05852791]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_W_all = grad_b_all @ X.swapaxes(1,2)\n",
    "grad_W = grad_W_all.mean(axis=0)\n",
    "grad_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "W -=  0.5 * grad_W\n",
    "b -=  0.5 * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1422345512581762"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 之前的 loss\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.054335231335711"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.exp(W @ X + b)\n",
    "q = d/d.sum(axis=(1,2), keepdims=True)\n",
    "loss = -np.log(q[range(len(y)), y])\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任務：全部合在一起\n",
    "    。設定W,b\n",
    "    。設定X\n",
    "    。訓練30次\n",
    "        > 計算q / loss\n",
    "        > 計算 grad_b / grad_W\n",
    "        > 更新 W / b\n",
    "    。看看更新後的準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]]]\n",
      "0 0.375\n",
      "1 0.4375\n",
      "2 0.375\n",
      "3 0.375\n",
      "4 0.375\n",
      "5 0.375\n",
      "6 0.375\n",
      "7 0.375\n",
      "8 0.3125\n",
      "9 0.3125\n",
      "10 0.3125\n",
      "11 0.3125\n",
      "12 0.3125\n",
      "13 0.375\n",
      "14 0.375\n",
      "15 0.375\n",
      "16 0.4375\n",
      "17 0.4375\n",
      "18 0.4375\n",
      "19 0.5\n",
      "20 0.5625\n",
      "21 0.6875\n",
      "22 0.6875\n",
      "23 0.75\n",
      "24 0.75\n",
      "25 0.75\n",
      "26 0.75\n",
      "27 0.8125\n",
      "28 0.8125\n",
      "29 0.8125\n",
      "30 0.8125\n",
      "31 0.8125\n",
      "32 0.8125\n",
      "33 0.8125\n",
      "34 0.8125\n",
      "35 0.8125\n",
      "36 0.8125\n",
      "37 0.8125\n",
      "38 0.8125\n",
      "39 0.8125\n",
      "40 0.8125\n",
      "41 0.8125\n",
      "42 0.875\n",
      "43 0.875\n",
      "44 0.875\n",
      "45 0.875\n",
      "46 0.875\n",
      "47 0.875\n",
      "48 0.875\n",
      "49 0.875\n"
     ]
    }
   ],
   "source": [
    "# 參考答案：https://github.com/tjwei/CrashCourseML/blob/master/DIY_NN/solutions/softmax_train.py\n",
    "W = Matrix(np.random.normal(size=(3,4)))\n",
    "b = Vector(np.random.normal(size=(3,)))\n",
    "X = np.array([Vector(*[(i>>j)%2 for j in range(4)]) for i in range(16)])\n",
    "y = np.array([i%3 for i in range(16)])\n",
    "one_y = np.eye(3)[y][..., None]\n",
    "print(one_y)\n",
    "# 紀錄 loss\n",
    "loss_history = []\n",
    "for epoch in range(50):\n",
    "    d = np.exp(W @ X + b)\n",
    "    q = d/d.sum(axis=(1,2), keepdims=True)\n",
    "    loss = -np.log(q[range(len(y)), y]).mean()\n",
    "    loss_history.append(loss)\n",
    "    accuracy = (q.argmax(axis=1).ravel() == y).mean()\n",
    "    print(epoch, accuracy)\n",
    "    grad_b_all = q - one_y\n",
    "    grad_b = grad_b_all.mean(axis=0)\n",
    "    grad_W_all = grad_b_all @ X.swapaxes(1,2)\n",
    "    grad_W = grad_W_all.mean(axis=0)\n",
    "    W -=  grad_W\n",
    "    b -= grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
